---
title: "Module 2 Lab"
output: pdf_document
---

This lab explores the error rate perils of simultaneous inference, and shows how two "correction" methods work.

# Bonferroni's Correction

First we examine coverage rates of t-based confidence intervals for the mean. To do this, we need to:

\begin{enumerate}
\item Generate the random variables
\item Calculate the confidence interval for the mean
\item Assess if the interval covers the true mean
\item Repeat the first three steps many times
\item Calculate the proportion of iterations in which the interval covers the true parameter value
\end{enumerate}

The following code carries out these steps. We should see very close to 95\% coverage.

```{r}
CI <- function(){
  X <- rnorm(50, 0, 1)          # Generate 50 N(0,1) random variables
  CI <- t.test(X)$conf.int      # Extract confidence interval from t.test()
  CI[1] < 0 & 0 < CI[2]         # Assess if CI covers true mean (TRUE/FALSE)
}
reps <- replicate(10000, CI())  # repeat many times
mean(reps)                      # Calculate proportion of CI's that contain true mean
```

Okay, that worked like it is supposed to; this part we already knew. What about simultaneous confidence intervals? Let's repeat the above steps, but with a few data sets. We will give each data set its own mean to avoid confusion, and help us follow the process. The question we are exploring: Does a family of 95\% confidence intervals cover their respective true parameters 95\% of the time?

```{r}
CI_simul <- function(){
  
  # Generate 50 N(0,1) random variables 3 times
  X1 <- rnorm(50, 0, 1)          
  X2 <- rnorm(50, 5, 1)          
  X3 <- rnorm(50, 10, 1)         
  
  # Extract each confidence interval from their individual t.test()
  CI1 <- t.test(X1)$conf.int      
  CI2 <- t.test(X2)$conf.int      
  CI3 <- t.test(X3)$conf.int 
  
  # Assess if all three CI's cover their true means (TRUE/FALSE)
  CI1[1] < 0 & 0 < CI1[2]  &         
  CI2[1] < 5 & 5 < CI2[2]  &
  CI3[1] < 10 & 10 < CI3[2]
  
}
reps_simul <- replicate(10000, CI_simul())  # repeat many times
# Calculate proportion of iterations where all three CI's contain their true mean
mean(reps_simul) 
```

The family of intervals has far less than 95\% coverage! In fact, very close to $(1 - \alpha)^3$ coverage, the result we expect if the three data sets (and confidence intervals) are independent. In this situation, we need a simultaneous inference correction. We need a correction because we want to be able to say "Our family of intervals collectively cover their true parameters 95\% of the time."

The Bonferroni correction increases the individual confidence intervals to $1 - \alpha/k$, where k is the number of intervals, to achieve a family-wise coverage of 95\%. 

```{r}
CI_simul_bonf <- function(){
  
  # Generate 50 N(0,1) random variables 3 times
  X1 <- rnorm(50, 0, 1)          
  X2 <- rnorm(50, 5, 1)          
  X3 <- rnorm(50, 10, 1)         
  
  # Increase each CI to "1 - 0.05/k", where k = 3 groups
  k <- 3
  CI1 <- t.test(X1, conf.level = 1 - 0.05/k)$conf.int      
  CI2 <- t.test(X2, conf.level = 1 - 0.05/k)$conf.int      
  CI3 <- t.test(X3, conf.level = 1 - 0.05/k)$conf.int 
  
  # Assess if all three CI's cover their true means (TRUE/FALSE)
  CI1[1] < 0 & 0 < CI1[2]  &         
  CI2[1] < 5 & 5 < CI2[2]  &
  CI3[1] < 10 & 10 < CI3[2]
  
}
reps_simul_bonf <- replicate(10000, CI_simul_bonf())  # repeat many times
# Calculate proportion of iterations where all three CI's contain their true mean
mean(reps_simul_bonf) 
```

We are back at 95\%!! The Bonferroni correction works in a wide range of situations, but it is our most conservative choice for controlling the family-wise error rates. Another option for multiple comparison correction is "Tukey's honest significant difference," or Tukey's HSD for short.

# Tukey's HSD

For this portion of the lab we use the data from the Module 1 homework with the heights of baseball, soccer, and basketball players. With whatever method you prefer, load in `Sports_Heights.csv`; it is included in the Module 2, Lab folder.

```{r}
Heights <- read.csv("Sport_Heights.csv", row.names = 1)
```

The data contains the height of players from the three different sports, and we want to answer the question: Do any two of the sports have the same mean height? The naive option is to calculate individual t-based confidence intervals for each of the three pairwise differences.

```{r}
# Create individual height vectors by sport
soccer <- subset(Heights, Sport == "soccer", "Height")$Height
baseball <- subset(Heights, Sport == "baseball", "Height")$Height
basketball <- subset(Heights, Sport == "basketball", "Height")$Height

# Individual confidence intervals
t.test(basketball, baseball, var.equal = FALSE)$conf.int
t.test(soccer, baseball, var.equal = FALSE)$conf.int
t.test(soccer, basketball, var.equal = FALSE)$conf.int
```

However, from the previous example, we know this set of intervals will not have a 95\% family-wise coverage rate. Therefore, we apply Tukey's correction, and compare.

`TukeyHSD` requires that its data come from a fitted model, so the first line of code below fits a model with the function `aov()`, which stands for "Analysis of Variance." Passing the `aov()` fit of `Height` against `Sport` tells `TukeyHSD` that `Height` is grouped by `Sport`.

```{r}
fit <- aov(Height ~ Sport, data = Heights) # aov = Analysis of Variance
summary(fit) # May look familiar!
TukeyHSD(fit) # Notice wider intervals
```

The first line fits the model and creates the Anova table returned by the second line. This table should look familiar from the Module 1 homework! The first line reminds you of the procedure being used, and the family-wise confidence level for the intervals calculated. Confidence intervals for the differences are provided in the table, in the columns labeled "`lwr`" and "`upr`." Notice that, as expected, they are all wider than their respective t-based non-corrected intervals. With these wider intervals, the family-wise coverage rate will be 95\% in repeated experiments. Also notice that the individual t-based confidence interval for the difference between mean soccer and baseball heights does not contain zero. However, the corrected interval does contain zero, meaning that we would reach different conclusions depending on the method used.

Food for thought--how would you use a simulation to explore the Tukey HSD corrected confidence interval coverage rates?

See Chapter 6 in "The Statistical Sleuth" for more details on Bonferroni, Tukey HSD, and other simultaneous inference correction procedures.
